# Modulo — Python per Data Analysis

## Panoramica del Modulo

Questo modulo ha coperto Python come strumento fondamentale per l'analisi dati, partendo dalle basi della programmazione fino ad arrivare a tecniche avanzate di manipolazione, pulizia e visualizzazione dei dati. Nel corso di quattro settimane intensive, ho costruito una solida competenza nell'uso di Python e delle sue librerie principali per l'analisi dati: Pandas, NumPy, Seaborn, Matplotlib e BeautifulSoup.

## Obiettivi del Modulo

- Padroneggiare i fondamenti di Python: variabili, strutture dati, logica e cicli
- Acquisire competenze avanzate in Pandas per la manipolazione di DataFrame
- Sviluppare tecniche di Data Cleaning per preparare dataset reali all'analisi
- Creare visualizzazioni efficaci con Seaborn e Matplotlib
- Comprendere le basi del Web Scraping per la raccolta dati dal web
- Applicare tutte le competenze in un progetto finale di analisi dati

## Settimane del Modulo

### Week 9 — Introduzione a Python: Variabili, Tipi di Dato, Collections, Logica e Loops

**Argomenti trattati:**
- Variabili e data types (int, float, str, bool, None)
- Funzioni built-in: `print()`, `type()`, `len()`, `help()`
- Liste, tuple, set e dizionari
- Costrutti logici: `if`, `elif`, `else`
- Cicli `while` e `for`
- Funzioni di iterazione: `range()`, `enumerate()`, `zip()`

**Competenze sviluppate:**
- Scrittura di algoritmi chiari e step-by-step
- Manipolazione di collezioni con indexing e slicing
- Controllo del flusso con `break` e `continue`
- Gestione ordinata di strutture dati complesse

**Sfide superate:**
- Differenza tra indexing e slicing
- Organizzazione precisa della logica condizionale
- Evitare loop infiniti e gestire correttamente le condizioni

### Week 10 — Analisi Dati con Pandas: DataFrame, Serie, Filtri, Null Handling, Groupby, Sorting

**Argomenti trattati:**
- Caricamento dati con `pd.read_csv()` e `pd.read_excel()`
- Ispezione dati: `.head()`, `.tail()`, `.shape()`, `.info()`, `.describe()`
- Serie vs DataFrame
- Selezione con `.loc[]` e `.iloc[]`
- Filtri logici con `&`, `|`, `~`
- Gestione valori nulli: `.isnull()`, `.dropna()`, `.fillna()`
- Aggregazioni con `groupby()` e `.agg()`

**Competenze sviluppate:**
- Analisi esplorativa di dataset reali
- Pulizia dati in modo replicabile
- Creazione di aggregazioni e statistiche sui gruppi
- Salvataggio di DataFrame trasformati

**Sfide superate:**
- Scegliere quando usare Serie vs DataFrame
- Costruire filtri multipli senza errori di parentesi
- Decidere la strategia corretta per i valori nulli in base al contesto

### Week 11 — Python: Advanced Pandas & Data Cleaning

**Argomenti trattati:**
- `groupby()` avanzato e MultiIndex
- Unione dati: `merge()`, `join()`, `concat()`
- Data Cleaning: duplicati, stringhe, valori nulli
- Manipolazione testo con metodi `.str`
- Automazione con libreria `os`
- AI-assisted coding con ChatGPT e Claude

**Competenze sviluppate:**
- Relazionare DataFrame diversi come in SQL
- Pulizia di colonne testuali (email, nomi)
- Iterazione su file multipli per analisi batch
- Utilizzo consapevole di LLM per debugging

**Sfide superate:**
- Gestire encoding (`latin1`) e separatori non standard
- Comprendere le differenze tra left, right, inner e outer join
- Scrivere script per scansionare cartelle automaticamente

### Week 12 — Python: Data Analysis, Visualization & Web Scraping

**Argomenti trattati:**
- EDA (Exploratory Data Analysis) completa
- Visualizzazione con Seaborn e Matplotlib
- Grafici: Boxplot, Histograms, Scatterplots, Heatmaps
- Gestione serie temporali (datetime)
- Web Scraping: HTML/CSS, BeautifulSoup, requests
- Progetto Finale: Analisi COVID-19

**Competenze sviluppate:**
- Creazione di grafici complessi per comunicare insight
- Analisi trend su serie temporali
- Estrazione dati da pagine web
- Combinazione di tutte le competenze in un progetto completo

**Sfide superate:**
- Scegliere il tipo di grafico più adatto per ogni relazione
- Gestire dataset di grandi dimensioni (OWID Covid)
- Interpretare la struttura DOM per estrarre informazioni specifiche

## Competenze Complessive Sviluppate

| Area | Competenza |
|------|------------|
| Programmazione | Fondamenti Python: variabili, strutture dati, logica, cicli |
| Data Manipulation | Pandas avanzato: filtering, grouping, merging, cleaning |
| Data Visualization | Grafici professionali con Seaborn e Matplotlib |
| Data Cleaning | Gestione valori nulli, duplicati, normalizzazione stringhe |
| Web Scraping | Estrazione dati dal web con BeautifulSoup |
| Automazione | Script per elaborazione batch di file multipli |
| AI-Assisted Coding | Utilizzo di LLM per debugging e ottimizzazione codice |

## File Principali del Modulo

| Settimana | File | Descrizione |
|-----------|------|-------------|
| 9 | `W9D1 - Teoria.pdf` | Variabili, tipi di dato, liste |
| 9 | `W9D1 - Pratica.pdf` | Esercizi su algoritmi e collezioni |
| 9 | `W9D2 - Teoria.pdf` | Tuple, set, dizionari, logica, loops |
| 10 | `W10D1 - Teoria.pdf` | DataFrame, Serie, indexing, null handling |
| 10 | `W10D4 - Teoria.pdf` | Sorting, groupby, aggregazioni |
| 10 | `W10D4 - Pratica.ipynb` | Esercizi su dataset reali |
| 11 | `W11D5 - Teoria.pdf` | Groupby avanzato, Merge/Join, AI coding |
| 11 | `W11D6 - Teoria.pdf` | Data Cleaning, stringhe, valori nulli |
| 11 | `W11D6 - Pratica.ipynb` | Script automazione e pulizia dati |
| 12 | `W12D7 - Teoria.pdf` | EDA e Data Visualization con Seaborn |
| 12 | `W12D8 - Teoria.pdf` | Web Scraping con BeautifulSoup |
| 12 | `W12D8 - Esame finale.ipynb` | Progetto Finale: Analisi COVID-19 |

## Conclusione

Il modulo Python ha rappresentato un percorso completo dalla programmazione di base all'analisi dati professionale. Partendo da variabili e cicli, sono arrivato a padroneggiare Pandas per la manipolazione di dataset complessi, a creare visualizzazioni efficaci con Seaborn e Matplotlib, e a raccogliere dati dal web con tecniche di scraping. L'aspetto più significativo è stato il Progetto Finale sul COVID-19, che ha richiesto di combinare tutte le competenze acquisite — pulizia dati, aggregazione, analisi temporale e visualizzazione comparativa — in un report coerente e professionale.

## Highlight

Il progetto finale sul COVID-19: partendo da un dataset grezzo di migliaia di righe, ho pulito i dati, aggregato per continenti e nazioni, analizzato trend temporali su casi, vaccini e ospedalizzazioni, e prodotto visualizzazioni comparative tra Italia, Germania e Francia — tutto in un unico notebook Python che racconta una storia chiara attraverso i dati.

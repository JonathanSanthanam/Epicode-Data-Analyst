# Modulo — Python per Data Analysis

## Panoramica del Modulo

Questo modulo ha coperto Python come strumento fondamentale per l'analisi dati, partendo dalle basi della programmazione fino ad arrivare a tecniche avanzate di manipolazione, pulizia e visualizzazione dei dati. Nel corso di quattro settimane intensive, ho costruito una solida competenza nell'uso di Python e delle sue librerie principali per l'analisi dati: Pandas, NumPy, Seaborn, Matplotlib e BeautifulSoup.

## Obiettivi del Modulo

- Padroneggiare i fondamenti di Python: variabili, strutture dati, logica e cicli
- Acquisire competenze avanzate in Pandas per la manipolazione di DataFrame
- Sviluppare tecniche di Data Cleaning per preparare dataset reali all'analisi
- Creare visualizzazioni efficaci con Seaborn e Matplotlib
- Comprendere le basi del Web Scraping per la raccolta dati dal web
- Applicare tutte le competenze in un progetto finale di analisi dati

## Settimane del Modulo

### Week 9 — Introduzione a Python: Variabili, Tipi di Dato, Collections, Logica e Loops

**Argomenti trattati:**
- Variabili e data types (int, float, str, bool, None)
- Funzioni built-in: `print()`, `type()`, `len()`, `help()`
- Liste, tuple, set e dizionari
- Costrutti logici: `if`, `elif`, `else`
- Cicli `while` e `for`
- Funzioni di iterazione: `range()`, `enumerate()`, `zip()`

**Competenze sviluppate:**
- Scrittura di algoritmi chiari e step-by-step
- Manipolazione di collezioni con indexing e slicing
- Controllo del flusso con `break` e `continue`
- Gestione ordinata di strutture dati complesse

**Sfide superate:**
- Differenza tra indexing e slicing
- Organizzazione precisa della logica condizionale
- Evitare loop infiniti e gestire correttamente le condizioni

### Week 10 — Analisi Dati con Pandas: DataFrame, Serie, Filtri, Null Handling, Groupby, Sorting

**Argomenti trattati:**
- Caricamento dati con `pd.read_csv()` e `pd.read_excel()`
- Ispezione dati: `.head()`, `.tail()`, `.shape()`, `.info()`, `.describe()`
- Serie vs DataFrame
- Selezione con `.loc[]` e `.iloc[]`
- Filtri logici con `&`, `|`, `~`
- Gestione valori nulli: `.isnull()`, `.dropna()`, `.fillna()`
- Aggregazioni con `groupby()` e `.agg()`

**Competenze sviluppate:**
- Analisi esplorativa di dataset reali
- Pulizia dati in modo replicabile
- Creazione di aggregazioni e statistiche sui gruppi
- Salvataggio di DataFrame trasformati

**Sfide superate:**
- Scegliere quando usare Serie vs DataFrame
- Costruire filtri multipli senza errori di parentesi
- Decidere la strategia corretta per i valori nulli in base al contesto

### Week 11 — Python: Advanced Pandas & Data Cleaning

**Argomenti trattati:**
- `groupby()` avanzato e MultiIndex
- Unione dati: `merge()`, `join()`, `concat()`
- Data Cleaning: duplicati, stringhe, valori nulli
- Manipolazione testo con metodi `.str`
- Automazione con libreria `os`
- AI-assisted coding con ChatGPT e Claude

**Competenze sviluppate:**
- Relazionare DataFrame diversi come in SQL
- Pulizia di colonne testuali (email, nomi)
- Iterazione su file multipli per analisi batch
- Utilizzo consapevole di LLM per debugging

**Sfide superate:**
- Gestire encoding (`latin1`) e separatori non standard
- Comprendere le differenze tra left, right, inner e outer join
- Scrivere script per scansionare cartelle automaticamente

### Week 12 — Python: Data Analysis, Visualization & Web Scraping

**Argomenti trattati:**
- EDA (Exploratory Data Analysis) completa
- Visualizzazione con Seaborn e Matplotlib
- Grafici: Boxplot, Histograms, Scatterplots, Heatmaps
- Gestione serie temporali (datetime)
- Web Scraping: HTML/CSS, BeautifulSoup, requests
- Progetto Finale: Analisi COVID-19

**Competenze sviluppate:**
- Creazione di grafici complessi per comunicare insight
- Analisi trend su serie temporali
- Estrazione dati da pagine web
- Combinazione di tutte le competenze in un progetto completo

**Sfide superate:**
- Scegliere il tipo di grafico più adatto per ogni relazione
- Gestire dataset di grandi dimensioni (OWID Covid)
- Interpretare la struttura DOM per estrarre informazioni specifiche

## Competenze Complessive Sviluppate

| Area | Competenza |
|------|------------|
| Programmazione | Fondamenti Python: variabili, strutture dati, logica, cicli |
| Data Manipulation | Pandas avanzato: filtering, grouping, merging, cleaning |
| Data Visualization | Grafici professionali con Seaborn e Matplotlib |
| Data Cleaning | Gestione valori nulli, duplicati, normalizzazione stringhe |
| Web Scraping | Estrazione dati dal web con BeautifulSoup |
| Automazione | Script per elaborazione batch di file multipli |
| AI-Assisted Coding | Utilizzo di LLM per debugging e ottimizzazione codice |

## File Principali del Modulo

| Settimana | File | Descrizione |
|-----------|------|-------------|
| 9 | `W9D1 - Teoria.pdf` | Variabili, tipi di dato, liste |
| 9 | `W9D1 - Pratica.pdf` | Esercizi su algoritmi e collezioni |
| 9 | `W9D2 - Teoria.pdf` | Tuple, set, dizionari, logica, loops |
| 10 | `W10D1 - Teoria.pdf` | DataFrame, Serie, indexing, null handling |
| 10 | `W10D4 - Teoria.pdf` | Sorting, groupby, aggregazioni |
| 10 | `W10D4 - Pratica.ipynb` | Esercizi su dataset reali |
| 11 | `W11D5 - Teoria.pdf` | Groupby avanzato, Merge/Join, AI coding |
| 11 | `W11D6 - Teoria.pdf` | Data Cleaning, stringhe, valori nulli |
| 11 | `W11D6 - Pratica.ipynb` | Script automazione e pulizia dati |
| 12 | `W12D7 - Teoria.pdf` | EDA e Data Visualization con Seaborn |
| 12 | `W12D8 - Teoria.pdf` | Web Scraping con BeautifulSoup |
| 12 | `W12D8 - Esame finale.ipynb` | Progetto Finale: Analisi COVID-19 |

## Conclusione

Il modulo Python ha rappresentato un percorso completo dalla programmazione di base all'analisi dati professionale. Partendo da variabili e cicli, sono arrivato a padroneggiare Pandas per la manipolazione di dataset complessi, a creare visualizzazioni efficaci con Seaborn e Matplotlib, e a raccogliere dati dal web con tecniche di scraping. L'aspetto più significativo è stato il Progetto Finale sul COVID-19, che ha richiesto di combinare tutte le competenze acquisite — pulizia dati, aggregazione, analisi temporale e visualizzazione comparativa — in un report coerente e professionale.

## Highlight

Il progetto finale sul COVID-19: partendo da un dataset grezzo di migliaia di righe, ho pulito i dati, aggregato per continenti e nazioni, analizzato trend temporali su casi, vaccini e ospedalizzazioni, e prodotto visualizzazioni comparative tra Italia, Germania e Francia — tutto in un unico notebook Python che racconta una storia chiara attraverso i dati.

---

# Module — Python for Data Analysis

## Module Overview

This module covered Python as a fundamental tool for data analysis, starting from programming basics up to advanced techniques for data manipulation, cleaning, and visualization. Over four intensive weeks, I built solid competence in using Python and its main data analysis libraries: Pandas, NumPy, Seaborn, Matplotlib, and BeautifulSoup.

## Module Objectives

- Master Python fundamentals: variables, data structures, logic, and loops
- Acquire advanced Pandas skills for DataFrame manipulation
- Develop Data Cleaning techniques to prepare real datasets for analysis
- Create effective visualizations with Seaborn and Matplotlib
- Understand Web Scraping basics for collecting data from the web
- Apply all skills in a final data analysis project

## Module Weeks

### Week 9 — Introduction to Python: Variables, Data Types, Collections, Logic, and Loops

**Topics covered:**
- Variables and data types (int, float, str, bool, None)
- Built-in functions: `print()`, `type()`, `len()`, `help()`
- Lists, tuples, sets, and dictionaries
- Logical structures: `if`, `elif`, `else`
- `while` and `for` loops
- Iteration functions: `range()`, `enumerate()`, `zip()`

**Skills developed:**
- Writing clear, step-by-step algorithms
- Manipulating collections with indexing and slicing
- Flow control with `break` and `continue`
- Organized handling of complex data structures

**Challenges overcome:**
- Difference between indexing and slicing
- Precise organization of conditional logic
- Avoiding infinite loops and managing conditions correctly

### Week 10 — Data Analysis with Pandas: DataFrames, Series, Filtering, Null Handling, Groupby, Sorting

**Topics covered:**
- Loading data with `pd.read_csv()` and `pd.read_excel()`
- Data inspection: `.head()`, `.tail()`, `.shape()`, `.info()`, `.describe()`
- Series vs DataFrame
- Selection with `.loc[]` and `.iloc[]`
- Logical filters with `&`, `|`, `~`
- Null value handling: `.isnull()`, `.dropna()`, `.fillna()`
- Aggregations with `groupby()` and `.agg()`

**Skills developed:**
- Exploratory analysis of real datasets
- Reproducible data cleaning
- Creating aggregations and group statistics
- Saving transformed DataFrames

**Challenges overcome:**
- Choosing when to use Series vs DataFrame
- Building multiple filters without parentheses errors
- Deciding the correct strategy for null values based on context

### Week 11 — Python: Advanced Pandas & Data Cleaning

**Topics covered:**
- Advanced `groupby()` and MultiIndex
- Data combining: `merge()`, `join()`, `concat()`
- Data Cleaning: duplicates, strings, null values
- Text manipulation with `.str` methods
- Automation with `os` library
- AI-assisted coding with ChatGPT and Claude

**Skills developed:**
- Relating different DataFrames like in SQL
- Cleaning text columns (emails, names)
- Iterating over multiple files for batch analysis
- Conscious use of LLMs for debugging

**Challenges overcome:**
- Handling encoding (`latin1`) and non-standard separators
- Understanding differences between left, right, inner, and outer joins
- Writing scripts to automatically scan folders

### Week 12 — Python: Data Analysis, Visualization & Web Scraping

**Topics covered:**
- Complete EDA (Exploratory Data Analysis)
- Visualization with Seaborn and Matplotlib
- Charts: Boxplots, Histograms, Scatterplots, Heatmaps
- Time series handling (datetime)
- Web Scraping: HTML/CSS, BeautifulSoup, requests
- Final Project: COVID-19 Analysis

**Skills developed:**
- Creating complex charts to communicate insights
- Trend analysis on time series
- Extracting data from web pages
- Combining all skills in a complete project

**Challenges overcome:**
- Choosing the most appropriate chart type for each relationship
- Managing large datasets (OWID Covid)
- Interpreting DOM structure to extract specific information

## Overall Skills Developed

| Area | Skill |
|------|-------|
| Programming | Python fundamentals: variables, data structures, logic, loops |
| Data Manipulation | Advanced Pandas: filtering, grouping, merging, cleaning |
| Data Visualization | Professional charts with Seaborn and Matplotlib |
| Data Cleaning | Handling null values, duplicates, string normalization |
| Web Scraping | Extracting data from the web with BeautifulSoup |
| Automation | Scripts for batch processing of multiple files |
| AI-Assisted Coding | Using LLMs for debugging and code optimization |

## Main Module Files

| Week | File | Description |
|------|------|-------------|
| 9 | `W9D1 - Teoria.pdf` | Variables, data types, lists |
| 9 | `W9D1 - Pratica.pdf` | Exercises on algorithms and collections |
| 9 | `W9D2 - Teoria.pdf` | Tuples, sets, dictionaries, logic, loops |
| 10 | `W10D1 - Teoria.pdf` | DataFrames, Series, indexing, null handling |
| 10 | `W10D4 - Teoria.pdf` | Sorting, groupby, aggregations |
| 10 | `W10D4 - Pratica.ipynb` | Exercises on real datasets |
| 11 | `W11D5 - Teoria.pdf` | Advanced groupby, Merge/Join, AI coding |
| 11 | `W11D6 - Teoria.pdf` | Data Cleaning, strings, null values |
| 11 | `W11D6 - Pratica.ipynb` | Automation scripts and data cleaning |
| 12 | `W12D7 - Teoria.pdf` | EDA and Data Visualization with Seaborn |
| 12 | `W12D8 - Teoria.pdf` | Web Scraping with BeautifulSoup |
| 12 | `W12D8 - Esame finale.ipynb` | Final Project: COVID-19 Analysis |

## Conclusion

The Python module represented a complete journey from basic programming to professional data analysis. Starting from variables and loops, I progressed to mastering Pandas for complex dataset manipulation, creating effective visualizations with Seaborn and Matplotlib, and collecting data from the web with scraping techniques. The most significant aspect was the COVID-19 Final Project, which required combining all acquired skills — data cleaning, aggregation, time-series analysis, and comparative visualization — into a coherent and professional report.

## Highlight

The COVID-19 final project: starting from a raw dataset of thousands of rows, I cleaned the data, aggregated by continents and nations, analyzed temporal trends on cases, vaccines, and hospitalizations, and produced comparative visualizations between Italy, Germany, and France — all in a single Python notebook that tells a clear story through data.
